\documentclass{article}

\usepackage{../fasy-hw}

\usepackage{ wasysym }

%% UPDATE these variables:
\renewcommand{\hwnum}{3}

\author{Group 13: Elliott Pryor, Ben Bushnell, Shengnan Zhou}
\collab{None}

\date{due: 18 October 2019}

\begin{document}

\nextprob
If 23 people are in a room, then the probability that at least two of them have
the same birthday is at least one half.  This is known as the birthday paradox,
since the number 23 is probably much lower than you would expect.  How many
people do we need in order to have 50\% probability that there are three people
with the same birthday?


% TODO: temp answer
\textbf{Answer: }  Using the Byron Schmuland's answer to estimate,

P(exactly 3 people have the same birthday with n people) = $1 - e^{-{n\choose 3}/365^2}$

We want the probability to be 50\%, therefore $0.5 = 1 - e^{-{n\choose 3}/365^2}$, $n = 83$.

Thus we will need at least 83 people for 3 people to have 50\% probability with the same birthday.


\nextprob
Suppose we have a graph $G=(V,E)$ and three colors, and randomly assign a color
each node (where each color is equally likely).
\begin{enumerate}
   \item What is the probability that every edge has two different colors on
        assigned to its two nodes?
        
        \textbf{Answer:} Let $G$ be a graph (assuming it to be a tree). And assume there are $n$ nodes and $n-1$ edges since $G$ is a tree.
        
        Total number of options of color choice is $3\choose 1$ $n$, and total number of options of different color choices is $3\choose 1$ $+ (n-1) $ $2\choose 1$
        
        Therefore the probability of two different colors is $P = \frac{3+2(n-1)}{3n} = \frac{2n+1}{3n}$.
        
        $P$ goes to $\frac{2}{3}$ as $n$ approaches infinity.
               
    \item What is the expected number of edges that have different colors
        assigned to its two nodes?
        
        \textbf{Answer:} As $n$ approaches infinity, $P=\frac{2}{3}$. We could argue that for a large graph/tree with $n$ nodes,  $\frac{2}{3}$ of the tree will have edges with different colored nodes. 
        
        Assuming the tree has $n$ nodes, then there will be $\frac{2}{3} (n-1)$ edges have different colors assigned to its two nodes.
        
\end{enumerate}

\nextprob
CLRS, Question 15-6.

\begin{algorithm}
    \caption{Guest List}\label{guests}
    \begin{algorithmic}[1]
    \Function{Guests}{$G$}
        \State guests\{\{\}\}
        \State vivality\{\}
        \For{$i$ in $[1, n]$}
			\State node = find next lowest node in graph
			\If{node doesn't have any children}
				\State guests[node] = \{node\}
				\State vivality[node] = node.vivality
			\Else
				\State $c = \sum_{child} vivality[child]$
				\State $g = node.vivality + \sum_{grandChild} vivality[grandChild]$
				\If{$c > g$}

					\State $guests[node] = \sum_{child} guests[child]$
					\State $vivality[node] = c$
				\Else
					\State $guests[node] = \{node\} + \sum_{grandChild} vivality[grandChild]$
					\State $vivality[node] = g$
				\EndIf
			\EndIf
		\EndFor

       \State \textbf{return} guests[root of tree]

    \EndFunction
    \end{algorithmic}
\end{algorithm}

This algorithm creates two lists that are indexed by the verticies of the graph. It then locates the node that is furthest down the tree that has not yet been explored. The if statement checks if the node is a leaf node. Otherwise, the optimal solution at that node is either one of two choices. The first one is if we choose the node and thus cannot choose the children, but we can choose the grandchildren. The second choice is if we do not choose the node so that we can choose the children. The second if statement takes care of these cases. This algorithm builds the optimal solution starting at the bottom nodes and builds up to the final solution.

The decrimenting function for the for loop would be $n - i$ this approaches zero as $i$
 approaches $n$. This maps to a well ordered set and decreases each itteration, and the algororithm therefore terminates.
 
 The runtime for this algorithm is $O(n^2)$. The loop repeats $n$ times. Inside the loop, the "find next lowest node in graph", as well as the summations all take $O(n)$ time. Thus, inside the loop is a summation of $O(n)$ processes, which is therefore also $O(n)$. So, an $O(n)$ process is repeated n times, and the overall runtime is $O(n^2)$.
 
 %TODO Loop invariant

 $L_i$ = guests[$v$] is the optimal solution with the head at $v$ $\forall v \in guests$ and vivality[$v$] is maximized and is the vivality produced from guests[$v$].
 
 Initiialization: guests = $\emptyset$ and thus $L_i$ is vacuously true
 Maintanance: There are three cases
 \begin{enumerate}[1.]
 \item The node is a leaf node. Then the optimal solution would consist of just the node.
 \item It is best to add this node. Then we add this node to the optimal solution, and can add the optimal solution of the grandchildren. This skips the child generation.
 \item It is best to skip this node. Then the optimal solution would be choosing the optimal solutions of the children.
 \end{enumerate}
 cases 2 and 3 are distinguished by determining which one produces a higher vivality score. The one that maximizes vivality is chosen. Therefore, the guest list that maximizes vivality is selected and the loop invariant holds.
 
 End: The loop ends when all nodes have been explored. Therefore, the last node explored (the root of the tree) contains the optimal solution and $L_i \rightarrow Q$.
 
 Termination: The decrimenting function is $n - i$. This approaches zero as $i$
 approaches $n$. This maps to a well ordered set and decreases each itteration, and the algorithm therefore terminates.


\nextprob
For the Greedy make change algorithm described in class on 10/02, describe the
problem and solution in your own words, including the use of pseudocode (with
more details than what was written in class).  Note: you do not need to give a
loop invariant and the proof of termination/runtime complexity.

\textbf{Answer:} The Greedy Make Change algorithm is used to solve an optimization problem. It has many solutions, but we wish to min/max some function defined over those solutions. The solutions are the different ways to make change. To optimize the solution means to minimize the number of coins used. And the solution might not be unique.

\textbf{Pseudocode:}
\begin{algorithm}
            \begin{algorithmic}
            \State $val$: the total value we want to make change from
            \State $d = [d_1, d_2, d_3, ......, d_k]$: a list of the changes we can make into (1 cent, 5 cents, 10 cents, etc.)
                \Function{GMC}{val: Integer, d: Array}
                    \State $S$: empty set to store the solution
                    \State sort $d$ from largest to smallest
                    \For{i = 1...k}
                        \State $count = val // d_i$
                        \State add $count$ of $d_i$ to $S$  \Comment{add as many $d_i$ as possible to $S$}
                    \EndFor
                    \newline
                    \Return $S$
                \EndFunction
            \end{algorithmic}
            \end{algorithm}

%TODO Decrementing Function, Runtime, Loop invariant

\nextprob
Suppose we have $n$ items hat we want to put in a knapsack of capacity $W$.  The i-th item has
weight $w_i$ and value $v_i$.  The knapsack can hold a total weight of $W$ and
we want to maximize the value of the items in the knapsack.
The \emph{0-1 knapsack problem} will assign each item one of two states: in the
knapsack, or not in the knapsack.  The \emph{fractional knapsack problem} allows
you to take a percentage of each item.

As a reminder, when giving an algorithm as an answer, you
are expected to give:
\begin{itemize}
    \item A prose explanation of the problem and algorithm.
    \item Psuedocode.
    \item The decrementing function for any loop or recursion, or a runtime
        justification.
    \item Justification of runtime.
    \item The loop invariant for any loops, with full justification.
\end{itemize}

\begin{enumerate}
    \item Give an $O(n\log n)$ greedy algorithm for the fractional knapsack problem.
      
This algorithm first sorts the items by the highest value:weight ratio. Then, if we can add the entire item we do (the if statement). Otherwise, we add a fraction of the item (the else statement). This fraction is the weight we have available over the item weight. 

\begin{algorithm}
    \caption{Fractional Knapsack Problem}\label{fracKnap}
    \begin{algorithmic}[1]
    \Function{fractionalKnapsack}{$n,W$}
      \State list = sort (n by $v_i/w_i$)
      \State knapsack = \{\}
      \For {item in list}
      	\If{$item.w < W$}
      		\State knapsack.add(item)
      		\State W -= item.w
      	\Else
      		\State knapsack.add(item * $\frac{W}{item.w}$
      		\State \textbf{break out of loop}
      	\EndIf
      \EndFor
      \State \textbf{return} knapsack
    \EndFunction
    \end{algorithmic}
\end{algorithm} 

This algorithm runs in O(nlogn) time. The sorting takes O(nlogn) time. The for loop runs n times, and has an inner complexity of O(1). Therefore the complexity of th for loop is O(n). The runtime of this algorithm is O(nlogn + n) which, assymtotically, is O(nlogn).

$P$ = the knapsack is empty, $Li$ = knapsack holds the i most valued items for the ith iteration, $Q$ = The knapsack holds $W$ of the most valued items, $G$ = items remain in the list, or the knapsack isn't full
    \begin{enumerate}
        \item Initialization: $P \implies L$, the knapsack is empty, therefore our optimal solution has not been reached.
        \item Maintenance: $L_{i} \land G \implies L_{i+1}$, The knapsack holds the i most valued items, is not full, and there are still items to choose from implies that we loop through again and choose another item.
        \item End: $L_{i} \land \neg G \implies Q$, The knapsack holds the i most valued items, and is full, or we have no other items to put into it implies our goal is accomplished.
        \item Termination: D\{space\} = $(1..length(n))$, is well ordered so the algorithm will terminate
    \end{enumerate}
    
    \item Give an $O(nW)$ time algorithm that uses dynamic programming to solve
        the 0-1 knapsack problem.
        
This algorithm solves the 0-1 knapsack problem. It uses an approach very similar to that used in the rod cutting algorithm. It keeps track of the items in the knapsack as well as their values in two lists. Then it itterates over each weight and finds the optimal solution. It initializes the knapsack and values to be the optimal solution of the previous example in the case that adding items would make the knapsack worse (ie. we already found the optimal solution for this weight). Then it goes through each item and tests if we can add it (doesn't exceede the weight) and if it would increase the value of the knapsack. If it meets both of these conditions we add it to the knapsack; otherwise, we do nothing.
        
\begin{algorithm}
    \caption{0-1 Knapsack Problem}\label{knap}
    \begin{algorithmic}[1]
    \Function{knapsack}{$n,W$}
      \State knapsack = \{\}
      \State values = \{\}
      \For {i in [1, W]}
      	\State values[i] = values[i-1]
      	\State knapsack[i] = knapsack[i-1]
      	\For{j in [1, n]}
      		\If{values[i] $<$ values[i-j.w] + j.v values[i] \textbf{and} W $\geq$ knapsack[i-j].w + j.w}
      			\State values[i] $\gets$ values[i-j] + j.v values[i]
      			\State knapsack[i] $\gets$ knapsack[i-j] + j
      		\EndIf
      	\EndFor
      \EndFor
      \State \textbf{return} knapsack
    \EndFunction
    \end{algorithmic}
\end{algorithm} 

The running time of this algorithm is O(nW). Inside of the inner loop the algorithm has a time complexity of O(1). This is repeated n times giving the inner loop a complexity of O(n). The inner loop repeats W times which results in the time complexity being O(Wn).

$P$ = The knapsack is empty, $Li$ = The knapsack is filled with items such that their combined weight $i \leq W$ and their combined value is maximized as a subset of the optimal solution, $Q$ = The knapsack is filled with items such that their combined weight $w \leq W$ and their combined value is maximized as an optimal solution, $G$ = there are still weights $i \leq W$ whose optimal solutions haven't been considered.
    \begin{enumerate}
        \item Initialization: $P \implies L$, 
        \item Maintenance: $L_{i} \land G \implies L_{i+1}$, 
        \item End: $L_{i} \land \neg G \implies Q$, 
        \item Termination: D\{space\} =  
    \end{enumerate}
        
\end{enumerate}

\end{document}
