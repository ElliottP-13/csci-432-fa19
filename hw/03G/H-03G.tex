\documentclass{article}
\usepackage{../fasy-hw}
\usepackage{ wasysym }

%% UPDATE these variables:
\renewcommand{\hwnum}{3}
\author{Group 13: Elliott Pryor, Ben Bushnell, }
\collab{None}
\date{due: 18 October 2019}

\begin{document}

\nextprob
If 23 people are in a room, then the probability that at least two of them have
the same birthday is at least one half.  This is known as the birthday paradox,
since the number 23 is probably much lower than you would expect.  How many
people do we need in order to have 50\% probability that there are three people
with the same birthday?


\nextprob
Suppose we have a graph $G=(V,E)$ and three colors, and randomly assign a color
each node (where each color is equally likely).
\begin{enumerate}
    \item What is the probability that every edge has two different colors on
        assigned to its two nodes?
    \item What is the expected number of edges that have different colors
        assigned to its two nodes?
\end{enumerate}

\nextprob
CLRS, Question 15-6.


\begin{algorithm}
    \caption{Guest List}\label{guests}
    \begin{algorithmic}[1]
    \Function{Guests}{$G$}
        \State guests\{\{\}\}
        \State vivality\{\}
        \For{$i$ in $[1, n]$}
			\State node = find next lowest node in graph
			\If{node doesn't have any children}
				\State guests[node] = \{node\}
				\State vivality[node] = node.vivality
			\Else
				\State $c = \sum_{child} vivality[child]$
				\State $g = node.vivality + \sum_{grandChild} vivality[grandChild]$
				
				\If{$c > g$}
					\State $guests[node] = \sum_{child} guests[child]$
					\State $vivality[node] = c$
				\Else
					\State $guests[node] = \{node\} + \sum_{grandChild} vivality[grandChild]$
					\State $vivality[node] = g$
				\EndIf
			\EndIf
		\EndFor
       \State \textbf{return} guests[root of tree]
    \EndFunction
    \end{algorithmic}
\end{algorithm}

This algorithm creates two lists that are indexed by the verticies of the graph. It then locates the node that is furthest down the tree that has not yet been explored. The if statement checks if the node is a leaf node. Otherwise, the optimal solution at that node is either one of two choices. The first one is if we choose the node and thus cannot choose the children, but we can choose the grandchildren. The second choice is if we do not choose the node so that we can choose the children. The second if statement takes care of these cases. This algorithm builds the optimal solution starting at the bottom nodes and builds up to the final solution.

The decrimenting function for the for loop would be $n - i$ this approaches zero as $i$
 approaches $n$. This maps to a well ordered set and decreases each itteration, and the algororithm therefore terminates.
 
 The runtime for this algorithm is $O(n^2)$. The loop repeats $n$ times. Inside the loop, the "find next lowest node in graph", as well as the summations all take $O(n)$ time. Thus, inside the loop is a summation of $O(n)$ processes, which is therefore also $O(n)$. So, an $O(n)$ process is repeated n times, and the overall runtime is $O(n^2)$.
 
 %TODO Loop invariant
 $L_i$ = guests[$v$] is the optimal solution with the head at $v$ $\forall v \in guests$ and vivality[$v$] is maximized and is the vivality produced from guests[$v$].
 
 Initiialization: guests = $\emptyset$ and thus $L_i$ is vacuously true
 Maintanance: There are three cases
 \begin{enumerate}[1.]
 \item The node is a leaf node. Then the optimal solution would consist of just the node.
 \item It is best to add this node. Then we add this node to the optimal solution, and can add the optimal solution of the grandchildren. This skips the child generation.
 \item It is best to skip this node. Then the optimal solution would be choosing the optimal solutions of the children.
 \end{enumerate}
 cases 2 and 3 are distinguished by determining which one produces a higher vivality score. The one that maximizes vivality is chosen. Therefore, the guest list that maximizes vivality is selected and the loop invariant holds.
 
 End: The loop ends when all nodes have been explored. Therefore, the last node explored (the root of the tree) contains the optimal solution and $L_i \rightarrow Q$.
 
 Termination: The decrimenting function is $n - i$. This approaches zero as $i$
 approaches $n$. This maps to a well ordered set and decreases each itteration, and the algorithm therefore terminates.

\nextprob
For the Greedy make change algorithm described in class on 10/02, describe the
problem and solution in your own words, including the use of pseudocode (with
more details than what was written in class).  Note: you do not need to give a
loop invariant and the proof of termination/runtime complexity.

\nextprob
Suppose we have $n$ items hat we want to put in a knapsack of capacity $W$.  The i-th item has
weight $w_i$ and value $v_i$.  The knapsack can hold a total weight of $W$ and
we want to maximize the value of the items in the knapsack.
The \emph{0-1 knapsack problem} will assign each item one of two states: in the
knapsack, or not in the knapsack.  The \emph{fractional knapsack problem} allows
you to take a percentage of each item.
\begin{enumerate}
    \item Give an $O(n\log n)$ greedy algorithm for the fractional knapsack problem.
    
%Sort by value/weight
%Add the items with highest value/weight ratio. 
%if out of space, add fraction of last item st. W is full    
    
    \item Give an $O(nW)$ time algorithm that uses dynamic programming to solve
        the 0-1 knapsack problem.
        
%I don't really know
%Solve this like the rod problem
%Start with weight of zero. --> optimal solution is no items
%increment weight
%then I get stuck
\end{enumerate}

\end{document}
